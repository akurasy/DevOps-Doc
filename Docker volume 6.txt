DOCKER VOLUME (Oct 15, 2022)

Docker Volume: Docker volumes are file systems mounted on Docker containers to preserve data generated by the running container.
 The data doesn't persist when that container no longer exists, and it can be difficult to get the data out of the container if another process needs it.

Let's say we have our application (springapp) that is talking to our database (Mongodb), launched on our Docker Engine/Docker Host or  EC2 instances. 
 We want  our database to be binded to the docker volume and not external volume, the docker volume we can bind to are ebs, efs, s3, ad or gpd. 
 Because we are doing AWS, we can mount our database on EBS (Elastic Block Service).

NOTE: Docker volume is a stateful application (that is you can provision an instance and mount or install the docker volume)

Networking:

Remember, when we created fintech network, we had what we called subnet.  e.g 
subnet: 172.18.0.0/16
		from the above subnet, we can have 2^(32-16) = 2^16 = 65,536

Network:
		subnet: 172.18.0.0/16,
		Gateway: 172.18.0.1

*By Default Docker Daemon determines the subnet prefix or allocate IP Address

When we create a mongodb, where does it store data??

 docker run --name some-mongo -v /my/own/datadir:/data/db -d mongo

 The above we copied from mongo documentation in dockerhub.com and this is path the mongo is saving the data.

 So what it means is that, we want to run the mongo container (name s0me-mongo) and put it in a volume (directory) called "-v /my/own/datadir" (-v indicates that, the path is now a volume) and then we are binding it to "/data/db -d mongo" where mongo initially stores the data temporarily.  Note: when we unbind our mongodb from our springapp, the data is lost.  Mounting or binding the volume to mongodb makes the data not to be lost?

 docker run --name some-mongo -v /my/own/datadir:/data/db -d mongo can be customized to:

 docker run --name some-mongo -v /home/ubuntu/data:/data/db -d mongo ( note: they are both the same)

the volume directory where we now want to bind our database path is called MOUNT POINT, and this is the directory path we want to bind our docker volume to = /data/db -d mongo  

 binding the local directory or volume to the database directory, this is called BIND MOUNT = /home/ubuntu/data:/data/db -d mongo, can also be binded to /tmp/mydata but issue is that, data can only be stored here temporarily.  Also, non-Docker process on the docker host or docker container can modify them at anytime when binded to the host (/home/ubuntu/data)
 
 Note: BIND MOUNT = /home/unbuntu/data: = (this is on the docker engine or DockerHost), could also be /tmp/mydata (this is on container)

CREATING A MOUNT POINT

 make a directory = mkdir data
 change directory to data = cd data

 then insert this into your mongodb commands from last class = -v /home/unbuntu/data/datadir:/data/db ( ensure to uncomment sprint app command if you are not running the dommand again).

 then run the script (ade.sh), this would bind mount to the database,

 run your data base with the new data

 delete/rremove the data base and then run the database appliation container againer, you would notice that the data came back

 This is a proof that the you have successfully bind mount the data on docker volume (here on the docker host)

 do ls data = you should see that datadir directory has been created automatically.

 then do ls datadir = this should list all the data files saved

 so if you do docker exec mongo26 ls /data/db = you would see the same data in "datadir", this is another proof that you have mounted the your database on the docker host

 Data persistency = this can occur if we have more than one mount point.

 The disadvantage of bind mounting our database on docker host or locally is that, non docker processes can modify the data, and the directory can be removed at anytime (with esclated privileges).


How to solve the above problem. (True Data Persistency)

-We want the volume to be fully managed by docker process. 

Two types of Volume:

-Local Volume = this is the volume we can create locally (see this as your local system storage)
-External volume = the is the volume we backup our data on externally (see this as external hardrive or googledrive)

LOCAL VOLUME:

do docker volume ls = this will list all docker local volume
Creating a local volume, run the command:
docker volume create -d local volume-name = this means, we want to create a volume, with the driver "local"
we can also try the above with another driver (remember how we create network? yes)

you can also create a volume by default in local drive;
docker volume create mongostore   
The difference between the above local volume we are trying to create and the "mkdir data" we did earlier is that, this is being managed by docker and former is being managed by us cos we made a directory etc.


Attaching the newly created local volume "mongostore" to the mount point = -v mongostore:/data/db (this will replace -v /home/ubuntu/data/datadir)

cons of the above is that, it is a docker process, and a simple rm -rf data wouldn't remove the data, only docker command can now delete the data.


EXTERNAL VOLUME

Where do we store data = /var/lib/docker/volumes

This process is fully managed by docker proceess.

To remove a volume, we do;

docker volume prune = this will remove all unattached volume

Creating external volume, we do;

docker volume create -d rexray <volumename>
There is something we call rexray.
before we run the above, we do the following;

Go to rexray.readthedocs.io/en/v0.9.1/user-guide/docker-plugins

read the documentation

then install it with the command

docker plugin install rexray/driver[:version] 
 OR 
docker plugin install rexray/driver:latest 
OR
use the EBS one, since it is what we are using;

docker plugin install rexray/ebs \
  EBS_ACCESSKEY=abc \
  EBS_SECRETKEY=123


Then configure your aws IAM user and grant permission for AmazonEC2fullAccess  

-search IAM
-Click the first IAM (just IAM)
-select user on the left pane
-select "Add user"
-enter username
-only check "Access key - Programmatic access" box
-click next to permission at bottom right
-on the permission page = select attach existing policies directly and on the same page search "AmazonEC2fullAccess" and check the box 
-proceed to "next tags", leave as is and next to review
-review the info on the "review page" and select "create user"
-once successful on the next page, download csv file, on the same page, reveal the secretkey and Access key ID.
-copy and replace in the rexray/EBS command (now see 

docker plugin install rexray/ebs \
  EBS_ACCESSKEY=AKIASNXR7DDE3UVVUOPI \
  EBS_SECRETKEY=dg9adBGnYmbTvKtgFomIAt2SUNq47gT2cxoviYKj

-next crreate the volume by copying and pasting the above command in your cli

-At this point, when the above is successful, if you do docker volume ls, it will only show the local volumes you have, and once you configure the external volume and run it, you would see it listed also.

-now do;

docker volume create --driver rexray/ebs --name ebsvolume

-now go back to your AWS console and search for ebs, on the list select "volume (EC2 feature) "
-next page will be a list of volumes, and "ebsvolume" you just created, managed by rexray
-and what we have done now is that, we are bind mounting our database to the external volume (not the dockerhost or docker engine this time)
-to confirm, remove your database (if you had one running already) 
-Now replace the local volume we created earlier "-v mongostore:/data/db \" with "-v ebsvolume:/data/db \" in "uat.sh"
-Done.


DELETING EBS VOLUME:

go to your ebsvolume on your aws console
-check the ebsvolume box and 


ASIDE: docker volume prune = to remove volume we are not using
ASIDE: registry stores docker images, volumes store data




 Pasting the spring app application and mongodb commands from last class:

 1-mongo database application (no need to expose the port number) : docker run -d --name mongopark --network fintech -v /home/unbuntu/data/datadir:/data/db \
-e MONGO_INITDB_ROOT_USERNAME=uatdb -e MONGO_INITDB_ROOT_PASSWORD=uatdb123 mongo 

Note: In mongo, there are environmental variables to pass them, we use "-e".  MONGO_INITDB_USERNAME=uatdb -e MONGO_INITDB_PASSWORD = : this is how MONGO syntax works for username and password.

Note: to use a database, you would need username (uatdb), password(uatdb123) and hostname (mongo26 (container name))


2-springbootmong application( we need to expose the port number) : docker run -d -p 8002:8080 --name springapp27 -e MONGO_DB_HOSTNAME=mongo26 \
-e MONGO_DB_USERNAME=uatdb -e MONGO_DB_PASSWORD=uatdb123 --network fintech \
acadalearning/spring-boot-mongo

3- To confirm that the application app is talking to the DB, do : docker exec <appcontainername> ping <DBcontainername or DBhostname> e.g docker exec springapp ping mongo26



BIG NOTE:  IN REAL LIFE,  WE DON'T USE DOCKER TO MANAGE CONTAINERS BECAUSE OF THE OBVIOUS PROBLEM, THERE IS ALWAYS ISSUES.  WE ONLY USE DOCKER TO CREATE IMAGES, AND K8 AND OTHER ORCHESTRATORS TO RUN CONTAINERS



Pushing Docker images to Dockerhub 

To push docker images to Docerhub we need username and password,

We can push to 
Azure
ECR = Elastic containeer Registry
GCP etc

Today we will be pushing to ECR

To do that, we need to create ECR account, 
-search ecr on aws search box
-Elastic container Registry will pop up, select it
-select create repository
-then select private
-click create repository
-Once that is created, click view push commands, 
-on your docker cli, do sudo apt install awscli
-follow the prompt, insert the authentication key in Key ID and Key password (did this by myself)
-It will then ask you for region, put the region on the top right of your aws account
-ask you for the output to show, enter and it will use the default.
-Once done, it will take you back to the ubuntu user



ASIDE:  
FROM jboss/wildfly:25.0.0.Final
COPY target/*.war /opt/jboss/wildfly/standalone/deployments/app.war